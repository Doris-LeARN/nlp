{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d4d2c7",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Forbes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691c738",
   "metadata": {},
   "source": [
    "#### WHAT IS KAFKA ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cc78d",
   "metadata": {},
   "source": [
    "Event streaming is the practice of capturing data in real-time from event sources like databases, sensors,\n",
    "mobile devices, cloud services, and software applications in the form of streams of events; storing these\n",
    "event streams durably for later retrieval; manipulating, processing, and reacting to the event streams in\n",
    "real-time as well as retrospectively; and routing the event streams to different destination technologies\n",
    "as needed. Event streaming thus ensures a continuous flow and interpretation of data so that the right\n",
    "information is at the right place, at the right time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d0c0da",
   "metadata": {},
   "source": [
    "#### EVENTS\n",
    "\n",
    "An event records the fact that “something happened” in the world or in your business. It is also called record\n",
    "or message in the documentation. When you read or write data to Kafka, you do this in the form of events.\n",
    "Conceptually, an event has a key, value, timestamp, and optional metadata headers. Here’s an example\n",
    "event:\n",
    "\n",
    "- Event key : \" Alice \"\n",
    "- Event value : \" Made a payment of $200 to Bob \"\n",
    "- Event timestamp : \" Jun . 25 , 2020 at 2:06 p . m .\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726aa38",
   "metadata": {},
   "source": [
    "#### PRODUCERS / CONSUMERS\n",
    "\n",
    "Producers are those client applications that publish (write) events to Kafka, and consumers are those that\n",
    "subscribe to (read and process) these events. In Kafka, producers and consumers are fully decoupled and\n",
    "agnostic of each other, which is a key design element to achieve the high scalability that Kafka is known for.\n",
    "For example, producers never need to wait for consumers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799bc3dd",
   "metadata": {},
   "source": [
    "#### TOPICS\n",
    "\n",
    "Events are organized and durably stored in topics. Topics in Kafka are always multi-producer and multisubscriber: a topic can have zero, one, or many producers that write events to it, as well as zero, one, or many\n",
    "consumers that subscribe to these events. Topics in Kafka are always multi-producer and multi-subscriber: a\n",
    "topic can have zero, one, or many producers that write events to it, as well as zero, one, or many consumers\n",
    "that subscribe to these events. Events in a topic can be read as often as needed, you define for how long\n",
    "Kafka should retain your events through a per-topic configuration setting, after which old events will be\n",
    "discarded.\n",
    "\n",
    "![Illustrations](image_kafka2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c33d7a",
   "metadata": {},
   "source": [
    "#### PROJECT SUMMARY\n",
    "\n",
    "The goal of this project is to create an end-to-end Machine Learning project, including :\n",
    "- extract tweets of specifics topics from Twitter, in real-time using Apache Kafka\n",
    "- transform, using you trained-model for sentiments analysis classification\n",
    "- load data into a data-warehouse using PostgreSQL\n",
    "- real-time dashboard, to monitor the results for each topics using PowerBI \n",
    "Each parts can be start independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abc282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import queue\n",
    "import time\n",
    "time.sleep(5) # Pause de 5 secondes après le chargement de la page\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import nltk\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from confluent_kafka import Producer, Consumer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from io import StringIO\n",
    "from xgboost import plot_importance\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "from sqlalchemy import create_engine, Column, Integer, String, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.dialects.postgresql import JSON\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import json\n",
    "from confluent_kafka import Producer, Consumer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec87ad6",
   "metadata": {},
   "source": [
    "#### EXTRACT\n",
    "\n",
    "First you need to install Kafka (and Zookeeper to manage it) on your system. At least 4GB of RAM is needed.\n",
    "You can use this tutorial : https://www.digitalocean.com/community/tutorials/how-to-install-apache-kafkaon-ubuntu-18-04\n",
    "You will use the website forbes.com and try to make your code generic in a way that it caters to multiple themes and publish them into the Kafka server using topics. You can have multiple #keyword to monitor for one specific show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d889322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(query):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(f\"https://www.forbes.com/search/?q={query}\")\n",
    "\n",
    "    # Temps pour que le bouton \"More articles\" soit cliquable\n",
    "    more_articles_button = WebDriverWait(driver, 30).until(\n",
    "        EC.element_to_be_clickable((By.CLASS_NAME, 'search-more'))\n",
    "    )\n",
    "\n",
    "    # Cliquer sur le bouton \"More articles\" jusqu'à ce qu'il n'y en ait plus\n",
    "    while more_articles_button:\n",
    "        try:\n",
    "            more_articles_button.click()\n",
    "            more_articles_button = WebDriverWait(driver, 30).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, 'search-more'))\n",
    "            )\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # Récupérer le contenu dès que tous les articles sont chargés\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    all_elt = soup.find_all(\"article\", class_=\"stream-item et-promoblock-removeable-item et-promoblock-star-item\")\n",
    "    titles = []\n",
    "    dates = []\n",
    "    url_articles = []\n",
    "    contents = []\n",
    "\n",
    "    # Récupération des contenus de chaque élément\n",
    "    for elt in all_elt:\n",
    "        title = elt.find(\"a\", class_=\"stream-item__title\").text\n",
    "\n",
    "        # Vérifier si l'élément a été trouvé\n",
    "        url_article_elt = elt.find(\"a\", class_=\"stream-item__image ratio16x9\")\n",
    "\n",
    "        if url_article_elt:\n",
    "            url_article = url_article_elt[\"href\"]\n",
    "        else:\n",
    "            url_article = \"Nan\"\n",
    "\n",
    "        content = elt.find(\"div\", class_=\"stream-item__description\").text\n",
    "        date = elt.find(\"div\", class_=\"stream-item__date\").text\n",
    "\n",
    "        # Ajout des contenus à la liste\n",
    "        titles.append(title)\n",
    "        dates.append(date)\n",
    "        contents.append(content)\n",
    "        url_articles.append(url_article)\n",
    "\n",
    "    # Fermer le navigateur après avoir terminé\n",
    "    driver.quit()\n",
    "\n",
    "    # Retourner un dictionnaire contenant les listes\n",
    "    return {\"Titles\": titles, \"Dates\": dates, \"Contents\": contents, \"URLs\": url_articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f35d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%3|1709208997.683|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709208998.684|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709208999.687|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209000.689|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209001.690|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209002.691|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209003.693|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209004.695|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1709209012.717|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209013.718|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209016.726|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209020.730|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209021.733|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209023.738|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209024.741|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209026.745|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209027.747|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209028.747|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209031.754|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209032.756|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209034.761|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209035.763|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209036.765|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209037.768|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1709209039.773|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209040.775|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209045.788|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209046.790|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209047.793|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209050.800|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209052.805|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209053.806|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209055.811|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209056.812|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209058.817|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209059.819|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209061.823|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209067.837|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209068.839|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1709209071.844|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209073.848|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209074.850|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209077.857|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209080.864|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%3|1709209082.868|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209084.872|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209086.877|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209089.886|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209091.886|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209093.889|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209094.892|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209095.894|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209097.898|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209098.904|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 5ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1709209099.900|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209100.902|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209107.921|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209109.926|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209110.927|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209113.936|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 2ms in state CONNECT)\n",
      "%3|1709209114.938|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209115.942|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209118.949|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209119.952|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209121.956|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209122.958|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209123.961|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209124.963|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209127.970|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209128.973|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209129.976|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1709209130.976|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209131.978|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209134.985|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209136.989|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1709209137.991|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209138.994|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209139.996|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209140.998|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209147.013|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 1ms in state CONNECT)\n",
      "%3|1709209148.014|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv6#[::1]:9092 failed: Connection refused (after 1ms in state CONNECT)\n"
     ]
    }
   ],
   "source": [
    "def produce_to_kafka(data_dict, kafka_bootstrap_servers='localhost:9092', kafka_topic='Forbes'):\n",
    "    # Configuration du producteur Kafka\n",
    "    kafka_producer_config = {\n",
    "        'bootstrap.servers': kafka_bootstrap_servers,\n",
    "        # D'autres configurations peuvent être ajoutées selon vos besoins\n",
    "    }\n",
    "\n",
    "    producer = Producer(kafka_producer_config)\n",
    "\n",
    "    try:\n",
    "        # Parcourir les données du dictionnaire et les publier dans Kafka\n",
    "        for i, record in enumerate(zip(data_dict[\"Titles\"], data_dict[\"Dates\"], data_dict[\"Contents\"], data_dict[\"URLs\"])):\n",
    "            title, date, content, url = record\n",
    "\n",
    "            # Construire un dictionnaire pour représenter un enregistrement\n",
    "            record_dict = {\n",
    "                'Title': title,\n",
    "                'Date': date,\n",
    "                'Content': content,\n",
    "                'URL': url\n",
    "            }\n",
    "\n",
    "            # Convertir le dictionnaire en chaîne JSON\n",
    "            json_message = json.dumps(record_dict)\n",
    "\n",
    "            # Publier le message dans le topic Kafka\n",
    "            producer.produce(kafka_topic, key=str(i), value=json_message)\n",
    "\n",
    "        # Attendre que tous les messages soient envoyés\n",
    "        producer.flush()\n",
    "\n",
    "        print(f\"Données publiées avec succès dans le topic {kafka_topic}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la publication dans Kafka : {e}\")\n",
    "\n",
    "# Appeler la fonction get_data avec le query \"Finance\"\n",
    "query = \"Finance\"\n",
    "data_dict = get_data(query)\n",
    "\n",
    "# Appeler la fonction produce_to_kafka avec le dictionnaire\n",
    "produce_to_kafka(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_from_kafka(kafka_bootstrap_servers='localhost:9092', kafka_topic='Forbes'):\n",
    "    consumer_config = {\n",
    "        'bootstrap.servers': kafka_bootstrap_servers,\n",
    "        'group.id': 'Jos_Gnon_Chim',  # Assurez-vous d'utiliser un nouveau groupe de consommateurs si nécessaire\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "\n",
    "    consumer = Consumer(consumer_config)\n",
    "    consumer.subscribe([kafka_topic])\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            msg = consumer.poll(timeout=1000)\n",
    "\n",
    "            if msg is None:\n",
    "                continue\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(msg.error())\n",
    "                    break\n",
    "\n",
    "            # Charger le message JSON\n",
    "            json_message = msg.value().decode('utf-8')\n",
    "            print(\"Message reçu :\")\n",
    "            print(json_message)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        consumer.close()\n",
    "\n",
    "# Appeler la fonction pour consommer depuis Kafka\n",
    "consume_from_kafka()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4fec4",
   "metadata": {},
   "source": [
    "#### TRANSFORM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b61a5f",
   "metadata": {},
   "source": [
    "First you need to create a Sentiment Analysis model with the IMDB database using Scikit-learn (or XGBoost).\n",
    "\n",
    "Dataset :  imdb.csv \n",
    "Using python, create a Kafka “consumer” with your trained-model to classify each articles from Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2742462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_with_encoding(file_path, encodings=['utf-8', 'latin-1', 'ISO-8859-1']):\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "                decoded_content = content.decode(encoding)\n",
    "            return pd.read_csv(StringIO(decoded_content), dtype=str)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise UnicodeDecodeError(f\"Unable to decode the file {file_path} with the provided encodings.\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "file_path = \"./imdb.csv\"\n",
    "data = read_csv_with_encoding(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_categorization(data):\n",
    "    \"\"\"\n",
    "    Cette fonction prend la donnée d'origine (data) et renvoie une version catégorisée de data.\n",
    "    Les classes sont représentées par des entiers.\n",
    "    \"\"\"\n",
    "    new_data = data.copy()\n",
    "    \n",
    "    # Convertir la colonne 'label' en minuscules et mapper les classes\n",
    "    print(f\"Type de données avant la conversion : {new_data['label'].dtype}\")\n",
    "    new_data['label'] = new_data['label'].str.lower().map({\"neg\": 0, \"pos\": 1, \"unsup\": 2})\n",
    "    \n",
    "    # Gérer la conversion de la colonne \"review\" en chaînes de caractères\n",
    "    new_data[\"review\"] = new_data[\"review\"].astype(str, errors='ignore')\n",
    "    \n",
    "    # Supprimer les échantillons avec 'unsup' comme label\n",
    "    new_data = new_data[new_data['label'] != 2]\n",
    "\n",
    "    # Afficher des informations sur les données après chaque étape\n",
    "    print(\"Informations sur les données après la conversion :\")\n",
    "    print(new_data.info())\n",
    "    \n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bade2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(data, label_column=\"label\", feature_columns=\"review\"):\n",
    "    \"\"\"\n",
    "    Cette fonction prend la donnée d'origine (data) et crée une version catégorisée de cette donnée.\n",
    "    Elle renvoie les données fractionnées (données d'entraînement et données de test).\n",
    "    \"\"\"\n",
    "    # Prétraitement des données\n",
    "    new_data = data_categorization(data)\n",
    "\n",
    "    # Vectorisation des données textuelles avec TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(new_data[feature_columns])\n",
    "\n",
    "    # Création du DataFrame avec les caractéristiques TF-IDF\n",
    "    df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Concaténation des caractéristiques TF-IDF avec les autres colonnes\n",
    "    df_processed = pd.concat([new_data[[label_column]], df_tfidf], axis=1)\n",
    "\n",
    "    # Séparation des ensembles de données d'entraînement et de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_processed.drop(label_column, axis=1),\n",
    "        df_processed[label_column],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = get_split_data(data)\n",
    "X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Cette fonction prend X_train et y_train et renvoie un modèle XGBoost entraîné sur ces derniers.\n",
    "    \"\"\"\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = get_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157635a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_standardization(X_train,X_test):\n",
    "    \"\"\"Cette fonction prend en paramètres X_train et X_test et retourne X_train et X_test standardisés\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled,X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled,X_test_scaled = data_standardization(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985551be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(model, X_test, y_test): \n",
    "    \"\"\"Cette fonction prend un modèle, un X_test, y_test et affiche les indicateurs de performances pour ce modèle\"\"\"\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Courbe ROC n'est pas applicable à la régression logistique, mais nous pouvons utiliser\n",
    "    # la distribution des probabilités prédites pour afficher la courbe ROC\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Tracer la courbe ROC avec Matplotlib\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='orange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nPerformance Indicators')\n",
    "    print(\"==========================================\")\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(model_set, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac1b829",
   "metadata": {},
   "source": [
    "#### LOAD\n",
    "\n",
    "Make another Kafka consumer to export articles and their label inside a PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38332124",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class KafkaMessage(Base):\n",
    "    __tablename__ = 'kafka_messages'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    topic = Column(String)\n",
    "    value = Column(JSON)\n",
    "    timestamp = Column(DateTime, default=datetime.utcnow)\n",
    "\n",
    "def connect_to_postgresql(user, password, host, port, database):\n",
    "    try:\n",
    "        conn = psycopg2.connect(user=user, password=password, host=host, port=port, database=database)\n",
    "        engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}')\n",
    "        return conn, engine\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la connexion à la base de données PostgreSQL : {e}\")\n",
    "        raise\n",
    "\n",
    "def init_db(db_url):\n",
    "    engine = create_engine(db_url)\n",
    "    Base.metadata.create_all(engine)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    return Session()\n",
    "\n",
    "def receive_events(consumer, topic):\n",
    "    consumer.subscribe(topic)  # Correction de la faute de frappe\n",
    "    ##while True:\n",
    "    msg = consumer.poll()\n",
    "    #if msg is None:\n",
    "    #continue\n",
    "    message = msg.value().decode(\"utf-8\")\n",
    "    return consumer\n",
    "\n",
    "def consume_and_save_to_db(consumer, session):\n",
    "    for message in consumer:\n",
    "        try:\n",
    "            json_value = json.loads(message.value.decode('utf-8'))\n",
    "            kafka_message = KafkaMessage(topic=message.topic, value=json_value)\n",
    "            session.add(kafka_message)\n",
    "            session.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la gestion du message : {str(e)}\")\n",
    "            session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092'\n",
    "}\n",
    "\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'wiada',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "producer = Producer(producer_config)\n",
    "consumer = Consumer(consumer_config)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "try:\n",
    "    db_config = {\n",
    "        'user': 'postgres',\n",
    "        'password': 'lola1205',\n",
    "        'host': 'localhost',\n",
    "        'port': '5432',\n",
    "        'database': 'postgres',\n",
    "    }\n",
    "\n",
    "    conn, engine = connect_to_postgresql(**db_config)\n",
    "    \n",
    "    db_session = init_db(engine)\n",
    "\n",
    "    # Utiliser la fonction pour consommer et enregistrer\n",
    "    consume_and_save_to_db(your_kafka_consumer, db_session)\n",
    "\n",
    "finally:\n",
    "    # Fermer la connexion lorsqu'elle n'est plus nécessaire\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16c706",
   "metadata": {},
   "source": [
    "#### REAL-TIME DASHBOARD\n",
    "\n",
    "Create one PowerBI dashboard connected on the Kafka in order to monitor in real-time the number of\n",
    "articles coming by topics\n",
    "Create another PowerBI conencted to the PostgreSQL database to monitor the results of your classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
