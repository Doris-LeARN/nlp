{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "494aefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import wordcloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a638e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Les bénéficiaires du programme de Women IA and Data Academy sont des amazones. Elles sont entrain d'apprendre la data visualisation, le machine learning, le deep learning, le web scraping et aussi tous les concepts de la data et de l'IA. Elles apprennent du fonctionnement complet des algorithmes jusqu'à la mise en place des modèles en passant bien sûr compte tenu de la récupération des données, le stockage de ces dernières et le streaming permettant d'avoir des visualisations à des fins BI\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\"Les bénéficiaires du programme de Women IA and Data Academy sont des amazones. Elles sont entrain d'apprendre la data visualisation, le machine learning, le deep learning, le web scraping et aussi tous les concepts de la data et de l'IA. Elles apprennent du fonctionnement complet des algorithmes jusqu'à la mise en place des modèles en passant bien sûr compte tenu de la récupération des données, le stockage de ces dernières et le streaming permettant d'avoir des visualisations à des fins BI\"\"\"\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "677cb247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"les bénéficiaires du programme de women ia and data academy sont des amazones. elles sont entrain d'apprendre la data visualisation, le machine learning, le deep learning, le web scraping et aussi tous les concepts de la data et de l'ia. elles apprennent du fonctionnement complet des algorithmes jusqu'à la mise en place des modèles en passant bien sûr compte tenu de la récupération des données, le stockage de ces dernières et le streaming permettant d'avoir des visualisations à des fins bi\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = corpus.lower()\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b842ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.replace(\",\", ' ').replace(\",\",' ').replace('\\n', \" \").replace(\"  \", \" \").replace(\"   \", \" \")\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b7c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_w = stopwords.words(\"french\")\n",
    "stop_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4287538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['les',\n",
       " 'bénéficiaires',\n",
       " 'du',\n",
       " 'programme',\n",
       " 'de',\n",
       " 'women',\n",
       " 'ia',\n",
       " 'and',\n",
       " 'data',\n",
       " 'academy',\n",
       " 'sont',\n",
       " 'des',\n",
       " 'amazones',\n",
       " '.',\n",
       " 'elles',\n",
       " 'sont',\n",
       " 'entrain',\n",
       " \"d'apprendre\",\n",
       " 'la',\n",
       " 'data',\n",
       " 'visualisation',\n",
       " ',',\n",
       " 'le',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'le',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'le',\n",
       " 'web',\n",
       " 'scraping',\n",
       " 'et',\n",
       " 'aussi',\n",
       " 'tous',\n",
       " 'les',\n",
       " 'concepts',\n",
       " 'de',\n",
       " 'la',\n",
       " 'data',\n",
       " 'et',\n",
       " 'de',\n",
       " \"l'ia\",\n",
       " '.',\n",
       " 'elles',\n",
       " 'apprennent',\n",
       " 'du',\n",
       " 'fonctionnement',\n",
       " 'complet',\n",
       " 'des',\n",
       " 'algorithmes',\n",
       " 'jusqu',\n",
       " \"'\",\n",
       " 'à',\n",
       " 'la',\n",
       " 'mise',\n",
       " 'en',\n",
       " 'place',\n",
       " 'des',\n",
       " 'modèles',\n",
       " 'en',\n",
       " 'passant',\n",
       " 'bien',\n",
       " 'sûr',\n",
       " 'compte',\n",
       " 'tenu',\n",
       " 'de',\n",
       " 'la',\n",
       " 'récupération',\n",
       " 'des',\n",
       " 'données',\n",
       " ',',\n",
       " 'le',\n",
       " 'stockage',\n",
       " 'de',\n",
       " 'ces',\n",
       " 'dernières',\n",
       " 'et',\n",
       " 'le',\n",
       " 'streaming',\n",
       " 'permettant',\n",
       " \"d'avoir\",\n",
       " 'des',\n",
       " 'visualisations',\n",
       " 'à',\n",
       " 'des',\n",
       " 'fins',\n",
       " 'bi']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(corpus)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58be3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf3b17cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le',\n",
       " 'bénéficiaires',\n",
       " 'du',\n",
       " 'programme',\n",
       " 'de',\n",
       " 'woman',\n",
       " 'ia',\n",
       " 'and',\n",
       " 'data',\n",
       " 'academy',\n",
       " 'sont',\n",
       " 'de',\n",
       " 'amazones',\n",
       " '.',\n",
       " 'elles',\n",
       " 'sont',\n",
       " 'entrain',\n",
       " \"d'apprendre\",\n",
       " 'la',\n",
       " 'data',\n",
       " 'visualisation',\n",
       " ',',\n",
       " 'le',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'le',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'le',\n",
       " 'web',\n",
       " 'scraping',\n",
       " 'et',\n",
       " 'aussi',\n",
       " 'tous',\n",
       " 'le',\n",
       " 'concept',\n",
       " 'de',\n",
       " 'la',\n",
       " 'data',\n",
       " 'et',\n",
       " 'de',\n",
       " \"l'ia\",\n",
       " '.',\n",
       " 'elles',\n",
       " 'apprennent',\n",
       " 'du',\n",
       " 'fonctionnement',\n",
       " 'complet',\n",
       " 'de',\n",
       " 'algorithmes',\n",
       " 'jusqu',\n",
       " \"'\",\n",
       " 'à',\n",
       " 'la',\n",
       " 'mise',\n",
       " 'en',\n",
       " 'place',\n",
       " 'de',\n",
       " 'modèles',\n",
       " 'en',\n",
       " 'passant',\n",
       " 'bien',\n",
       " 'sûr',\n",
       " 'compte',\n",
       " 'tenu',\n",
       " 'de',\n",
       " 'la',\n",
       " 'récupération',\n",
       " 'de',\n",
       " 'données',\n",
       " ',',\n",
       " 'le',\n",
       " 'stockage',\n",
       " 'de',\n",
       " 'ce',\n",
       " 'dernières',\n",
       " 'et',\n",
       " 'le',\n",
       " 'streaming',\n",
       " 'permettant',\n",
       " \"d'avoir\",\n",
       " 'de',\n",
       " 'visualisation',\n",
       " 'à',\n",
       " 'de',\n",
       " 'fin',\n",
       " 'bi']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [lemmatizer.lemmatize(k) for k in tokens]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d7ae5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eaten'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"eaten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3251e51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PorterStemmer>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt = PorterStemmer()\n",
    "elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06287fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scrape'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt.stem(\"scraping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31738091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'invit'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt.stem(\"invited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "428480a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'le': 7,\n",
       " 'bénéficiaires': 1,\n",
       " 'du': 2,\n",
       " 'programme': 1,\n",
       " 'de': 11,\n",
       " 'woman': 1,\n",
       " 'ia': 1,\n",
       " 'and': 1,\n",
       " 'data': 3,\n",
       " 'academy': 1,\n",
       " 'sont': 2,\n",
       " 'amazones': 1,\n",
       " '.': 2,\n",
       " 'elles': 2,\n",
       " 'entrain': 1,\n",
       " \"d'apprendre\": 1,\n",
       " 'la': 4,\n",
       " 'visualisation': 2,\n",
       " ',': 4,\n",
       " 'machine': 1,\n",
       " 'learning': 2,\n",
       " 'deep': 1,\n",
       " 'web': 1,\n",
       " 'scraping': 1,\n",
       " 'et': 3,\n",
       " 'aussi': 1,\n",
       " 'tous': 1,\n",
       " 'concept': 1,\n",
       " \"l'ia\": 1,\n",
       " 'apprennent': 1,\n",
       " 'fonctionnement': 1,\n",
       " 'complet': 1,\n",
       " 'algorithmes': 1,\n",
       " 'jusqu': 1,\n",
       " \"'\": 1,\n",
       " 'à': 2,\n",
       " 'mise': 1,\n",
       " 'en': 2,\n",
       " 'place': 1,\n",
       " 'modèles': 1,\n",
       " 'passant': 1,\n",
       " 'bien': 1,\n",
       " 'sûr': 1,\n",
       " 'compte': 1,\n",
       " 'tenu': 1,\n",
       " 'récupération': 1,\n",
       " 'données': 1,\n",
       " 'stockage': 1,\n",
       " 'ce': 1,\n",
       " 'dernières': 1,\n",
       " 'streaming': 1,\n",
       " 'permettant': 1,\n",
       " \"d'avoir\": 1,\n",
       " 'fin': 1,\n",
       " 'bi': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_infos = {k: tokens.count(k) for k in tokens}\n",
    "dict_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ceeb01a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dict_infos)\n\u001b[1;32m      2\u001b[0m data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:645\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[1;32m    648\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(dict_infos)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc6e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
