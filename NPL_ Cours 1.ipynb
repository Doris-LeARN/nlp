{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b78fef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Chimène\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chimène\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chimène\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "# from wordcloud import wordcloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b69ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Les bénéficiaires du programme de Women  ia et data academy sont des amazones. elles sont entrain d'apprendre la  data visualisation, le  machine learning, le deep learning le web scraping et aussi les concepts de data et de l'ia  elles apprennent le fonctionnement complet des algos jusqu'à la mise en place des modèles en tenant par bien sûr compte de la récupération des données, le stockage de ces dernières et le streaming permettant d'avoir des visualisations à des fins biens.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b9b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"les bénéficiaires du programme de women  ia et data academy sont des amazones. elles sont entrain d'apprendre la  data visualisation, le  machine learning, le deep learning le web scraping et aussi les concepts de data et de l'ia  elles apprennent le fonctionnement complet des algos jusqu'à la mise en place des modèles en tenant par bien sûr compte de la récupération des données, le stockage de ces dernières et le streaming permettant d'avoir des visualisations à des fins biens.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e717e19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"les bénéficiaires du programme de women  ia et data academy sont des amazones  elles sont entrain d'apprendre la  data visualisation le  machine learning le deep learning le web scraping et aussi les concepts de data et de l'ia  elles apprennent le fonctionnement complet des algos jusqu'à la mise en place des modèles en tenant par bien sûr compte de la récupération des données le stockage de ces dernières et le streaming permettant d'avoir des visualisations à des fins biens \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text.replace(\".\",'').replace(\",\",\"\").replace('\\n',\"\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bc462d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_w = stopwords.words(\"french\")\n",
    "stop_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b4665da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['les',\n",
       " 'bénéficiaires',\n",
       " 'du',\n",
       " 'programme',\n",
       " 'de',\n",
       " 'women',\n",
       " 'ia',\n",
       " 'et',\n",
       " 'data',\n",
       " 'academy',\n",
       " 'sont',\n",
       " 'des',\n",
       " 'amazones',\n",
       " 'elles',\n",
       " 'sont',\n",
       " 'entrain',\n",
       " \"d'apprendre\",\n",
       " 'la',\n",
       " 'data',\n",
       " 'visualisation',\n",
       " 'le',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'le',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'le',\n",
       " 'web',\n",
       " 'scraping',\n",
       " 'et',\n",
       " 'aussi',\n",
       " 'les',\n",
       " 'concepts',\n",
       " 'de',\n",
       " 'data',\n",
       " 'et',\n",
       " 'de',\n",
       " \"l'ia\",\n",
       " 'elles',\n",
       " 'apprennent',\n",
       " 'le',\n",
       " 'fonctionnement',\n",
       " 'complet',\n",
       " 'des',\n",
       " 'algos',\n",
       " 'jusqu',\n",
       " \"'\",\n",
       " 'à',\n",
       " 'la',\n",
       " 'mise',\n",
       " 'en',\n",
       " 'place',\n",
       " 'des',\n",
       " 'modèles',\n",
       " 'en',\n",
       " 'tenant',\n",
       " 'par',\n",
       " 'bien',\n",
       " 'sûr',\n",
       " 'compte',\n",
       " 'de',\n",
       " 'la',\n",
       " 'récupération',\n",
       " 'des',\n",
       " 'données',\n",
       " 'le',\n",
       " 'stockage',\n",
       " 'de',\n",
       " 'ces',\n",
       " 'dernières',\n",
       " 'et',\n",
       " 'le',\n",
       " 'streaming',\n",
       " 'permettant',\n",
       " \"d'avoir\",\n",
       " 'des',\n",
       " 'visualisations',\n",
       " 'à',\n",
       " 'des',\n",
       " 'fins',\n",
       " 'biens']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "216388bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03d699f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le',\n",
       " 'bénéficiaires',\n",
       " 'du',\n",
       " 'programme',\n",
       " 'de',\n",
       " 'woman',\n",
       " 'ia',\n",
       " 'et',\n",
       " 'data',\n",
       " 'academy',\n",
       " 'sont',\n",
       " 'de',\n",
       " 'amazones',\n",
       " 'elles',\n",
       " 'sont',\n",
       " 'entrain',\n",
       " \"d'apprendre\",\n",
       " 'la',\n",
       " 'data',\n",
       " 'visualisation',\n",
       " 'le',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'le',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'le',\n",
       " 'web',\n",
       " 'scraping',\n",
       " 'et',\n",
       " 'aussi',\n",
       " 'le',\n",
       " 'concept',\n",
       " 'de',\n",
       " 'data',\n",
       " 'et',\n",
       " 'de',\n",
       " \"l'ia\",\n",
       " 'elles',\n",
       " 'apprennent',\n",
       " 'le',\n",
       " 'fonctionnement',\n",
       " 'complet',\n",
       " 'de',\n",
       " 'algos',\n",
       " 'jusqu',\n",
       " \"'\",\n",
       " 'à',\n",
       " 'la',\n",
       " 'mise',\n",
       " 'en',\n",
       " 'place',\n",
       " 'de',\n",
       " 'modèles',\n",
       " 'en',\n",
       " 'tenant',\n",
       " 'par',\n",
       " 'bien',\n",
       " 'sûr',\n",
       " 'compte',\n",
       " 'de',\n",
       " 'la',\n",
       " 'récupération',\n",
       " 'de',\n",
       " 'données',\n",
       " 'le',\n",
       " 'stockage',\n",
       " 'de',\n",
       " 'ce',\n",
       " 'dernières',\n",
       " 'et',\n",
       " 'le',\n",
       " 'streaming',\n",
       " 'permettant',\n",
       " \"d'avoir\",\n",
       " 'de',\n",
       " 'visualisation',\n",
       " 'à',\n",
       " 'de',\n",
       " 'fin',\n",
       " 'biens']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [lemmatizer.lemmatize(k) for k in tokens]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2bfa14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eaten'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"eaten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccda8cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PorterStemmer>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt = PorterStemmer()\n",
    "elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "426c4d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scrape'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt.stem(\"scraping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdcc5830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'invit'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt.stem(\"invited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2db0a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'le': 8,\n",
       " 'bénéficiaires': 1,\n",
       " 'du': 1,\n",
       " 'programme': 1,\n",
       " 'de': 11,\n",
       " 'woman': 1,\n",
       " 'ia': 1,\n",
       " 'et': 4,\n",
       " 'data': 3,\n",
       " 'academy': 1,\n",
       " 'sont': 2,\n",
       " 'amazones': 1,\n",
       " 'elles': 2,\n",
       " 'entrain': 1,\n",
       " \"d'apprendre\": 1,\n",
       " 'la': 3,\n",
       " 'visualisation': 2,\n",
       " 'machine': 1,\n",
       " 'learning': 2,\n",
       " 'deep': 1,\n",
       " 'web': 1,\n",
       " 'scraping': 1,\n",
       " 'aussi': 1,\n",
       " 'concept': 1,\n",
       " \"l'ia\": 1,\n",
       " 'apprennent': 1,\n",
       " 'fonctionnement': 1,\n",
       " 'complet': 1,\n",
       " 'algos': 1,\n",
       " 'jusqu': 1,\n",
       " \"'\": 1,\n",
       " 'à': 2,\n",
       " 'mise': 1,\n",
       " 'en': 2,\n",
       " 'place': 1,\n",
       " 'modèles': 1,\n",
       " 'tenant': 1,\n",
       " 'par': 1,\n",
       " 'bien': 1,\n",
       " 'sûr': 1,\n",
       " 'compte': 1,\n",
       " 'récupération': 1,\n",
       " 'données': 1,\n",
       " 'stockage': 1,\n",
       " 'ce': 1,\n",
       " 'dernières': 1,\n",
       " 'streaming': 1,\n",
       " 'permettant': 1,\n",
       " \"d'avoir\": 1,\n",
       " 'fin': 1,\n",
       " 'biens': 1}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_infos = {k: tokens.count(k) for k in tokens}\n",
    "dict_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3a31529",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(dict_infos)\n\u001b[0;32m      2\u001b[0m data\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:645\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    648\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(dict_infos)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57ab78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
